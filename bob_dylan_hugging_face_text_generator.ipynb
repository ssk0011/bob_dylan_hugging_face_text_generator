{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f924d54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>release_year</th>\n",
       "      <th>album</th>\n",
       "      <th>title</th>\n",
       "      <th>lyrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1961</td>\n",
       "      <td>The Bootleg Series, Vol 1-3: Rare &amp; Unreleased...</td>\n",
       "      <td>Hard Times In New York Town</td>\n",
       "      <td>Come you ladies and you gentlemen, a-listen to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1961</td>\n",
       "      <td>The Bootleg Series, Vol 1-3: Rare &amp; Unreleased...</td>\n",
       "      <td>Man on the street</td>\n",
       "      <td>â€™ll sing you a song, ainâ€™t very long\\n\\nâ€™Bout ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1962</td>\n",
       "      <td>The Bootleg Series, Vol 1-3: Rare &amp; Unreleased...</td>\n",
       "      <td>Talkinâ€™ Bear Mountain Picnic Massacre Blues</td>\n",
       "      <td>I saw it advertised one day\\n\\nBear Mountain p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1962</td>\n",
       "      <td>The Bootleg Series, Vol 1-3: Rare &amp; Unreleased...</td>\n",
       "      <td>Let Me Die in My Footsteps</td>\n",
       "      <td>I will not go down under the ground\\n\\nâ€™Cause ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1962</td>\n",
       "      <td>The Bootleg Series, Vol 1-3: Rare &amp; Unreleased...</td>\n",
       "      <td>Rambling, Gambling Willie</td>\n",
       "      <td>Come around you rovinâ€™ gamblers and a story I ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   release_year                                              album  \\\n",
       "0          1961  The Bootleg Series, Vol 1-3: Rare & Unreleased...   \n",
       "1          1961  The Bootleg Series, Vol 1-3: Rare & Unreleased...   \n",
       "2          1962  The Bootleg Series, Vol 1-3: Rare & Unreleased...   \n",
       "3          1962  The Bootleg Series, Vol 1-3: Rare & Unreleased...   \n",
       "4          1962  The Bootleg Series, Vol 1-3: Rare & Unreleased...   \n",
       "\n",
       "                                         title  \\\n",
       "0                  Hard Times In New York Town   \n",
       "1                            Man on the street   \n",
       "2  Talkinâ€™ Bear Mountain Picnic Massacre Blues   \n",
       "3                   Let Me Die in My Footsteps   \n",
       "4                    Rambling, Gambling Willie   \n",
       "\n",
       "                                              lyrics  \n",
       "0  Come you ladies and you gentlemen, a-listen to...  \n",
       "1  â€™ll sing you a song, ainâ€™t very long\\n\\nâ€™Bout ...  \n",
       "2  I saw it advertised one day\\n\\nBear Mountain p...  \n",
       "3  I will not go down under the ground\\n\\nâ€™Cause ...  \n",
       "4  Come around you rovinâ€™ gamblers and a story I ...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file\n",
    "df = pd.read_csv('./bob dylan corpus.csv')\n",
    "\n",
    "# Show the first few rows to understand the structure\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92a78989",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Come you ladies and you gentlemen, a-listen to my song\\nSing it to you right, but you might think itâ€™s wrong\\nJust a little glimpse of a story Iâ€™ll tell\\nâ€™Bout an East Coast city that you all know well\\nItâ€™s hard times in the city\\nLivinâ€™ down in New York town\\n\\nOld New York City is a friendly old town\\nFrom Washington Heights to Harlem on down\\nThereâ€™s a-mighty many people all millinâ€™ all around\\nTheyâ€™ll kick you when youâ€™re up and knock you when youâ€™re down\\nItâ€™s hard times in the city\\nLivinâ€™ down in Ne'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine all lyrics into a single string\n",
    "all_lyrics = \"\\n\".join(df['lyrics'].dropna())\n",
    "all_lyrics = all_lyrics.replace(\"\\n\\n\",\"\\n\")\n",
    "# Check the first 500 characters to see a snippet\n",
    "all_lyrics[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e539c09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"all_lyrics.txt\", \"w\") as text_file:\n",
    "    text_file.write(all_lyrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2f1ff21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sunil/miniconda3/envs/personal/lib/python3.9/site-packages/transformers/data/datasets/language_modeling.py:54: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm.py\n",
      "  warnings.warn(\n",
      "/Users/sunil/miniconda3/envs/personal/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 1268\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 40\n",
      "  Number of trainable parameters = 354823168\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='40' max='40' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [40/40 09:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=40, training_loss=3.0125118255615235, metrics={'train_runtime': 557.9066, 'train_samples_per_second': 2.273, 'train_steps_per_second': 0.072, 'total_flos': 294398120165376.0, 'train_loss': 3.0125118255615235, 'epoch': 1.0})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Required Imports\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer, TextDataset, DataCollatorForLanguageModeling\n",
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "# Load a pre-trained GPT-2 model and tokenizer\n",
    "model_name = \"gpt2-medium\"\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Tokenize the lyrics and prepare dataset\n",
    "train_dataset = TextDataset(\n",
    "    tokenizer=tokenizer,\n",
    "    file_path=\"./all_lyrics.txt\",  # Save the all_lyrics string to a file and provide its path here\n",
    "    block_size=128\n",
    ")\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer,\n",
    "    mlm=False\n",
    ")\n",
    "\n",
    "# Training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=32,\n",
    "    save_steps=10_000,\n",
    "    save_total_limit=2,\n",
    ")\n",
    "\n",
    "# Initialize the Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=train_dataset,\n",
    ")\n",
    "\n",
    "# Train\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de608adc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Text 1: In a cosmic sort of way\n",
      "Well, I'll just make sure everybody's just fine\n",
      "They'll be fine just about anything\n",
      "They can make the world a better place too\n",
      "Well, I'll just make sure everybody's just fine\n",
      "\n",
      "They'll be fine just about anything\n",
      "They can make the world a better place too\n",
      "The only thing I know\n",
      "This is me and I don't know\n",
      "I feel really bad\n",
      "Well, I'll just make sure everybody's just fine\n",
      "\n",
      "\n",
      "Generated Text 2: In a cosmic sort of way, I donâ€™t know, what are you thinkingâ€™t doing here?\n",
      "Thereâ€™s no one here to help\n",
      "Iâ€™m the one who has taken the place of all\n",
      "And Iâ€™m the one who was born on the bottom of the world\n",
      "The sun just set, it was just kind of a sad thing\n",
      "What did you do, you wonder, that youâ€™d put up that wall and you made\n",
      "\n",
      "Generated Text 3: In a cosmic sort of way, maybe I can keep everything the same, but I can't keep everything the same\n",
      "I could always say I can go to heaven, but I can't bring myself to believe\n",
      "Can't be the same for me, can't be the same for you\n",
      "I can make you smile all the time, I donâ€™t have to worry about anyone,\n",
      "I can make you believe anything you want to believe\n",
      "Iâ€™ll help you find something in\n",
      "\n",
      "Generated Text 4: In a cosmic sort of way, yes, it's so pretty, oh, but it is so cold and just flat\n",
      "\n",
      "\n",
      "And the birds are jumping around the trees\n",
      "And the animals are flying, they're flying around the hills\n",
      "\n",
      "They're playing a game with the kids, they're playing a game with each other\n",
      "\n",
      "It's all so very sweet\n",
      "It's all so very sweet\n",
      "\n",
      "It's all very sweet\n",
      "\n",
      "Well, I think it's been a while\n",
      "\n",
      "Generated Text 5: In a cosmic sort of way.\n",
      " \n",
      " \n",
      " \n",
      " It seems to be a kind of thing that I donâ€™t understand,\n",
      " If you got it all wrong with one hand\n",
      " \n",
      " When you were a kid you had it all wrong\n",
      " \n",
      " Youâ€™re a fool to believe that you can do\n",
      " \n",
      " Something so wrong you think it canâ€™t be done\n",
      " \n",
      " \n",
      " \n",
      " You know you canâ€™t do something like\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate text\n",
    "input_text = \"In a cosmic sort of way\"\n",
    "input_ids = tokenizer.encode(input_text, return_tensors='pt')\n",
    "\n",
    "output = model.generate(input_ids, max_length=100, num_return_sequences=5, temperature=0.9, do_sample=True)\n",
    "\n",
    "for i, text in enumerate(output):\n",
    "    print(f\"Generated Text {i+1}: {tokenizer.decode(text)}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7855bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
